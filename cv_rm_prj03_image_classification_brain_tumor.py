# -*- coding: utf-8 -*-
"""cv-rm-prj03-image-classification-brain-tumor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16w-F9eDe06GWe2v_gZ9m1mlhBKs9thkg

<br>

# Loading Dataset - Add dataset from Add Input Option

<br>
"""

import os

path = "/kaggle/input/brain-tumor-mri-dataset/"
print(os.listdir(path))

"""<br>

# Show main folder ‚Üí subfolders ‚Üí sub-subfolders (2 levels only)

<br>
"""

import os

base = "/kaggle/input/brain-tumor-mri-dataset"

for root, dirs, files in os.walk(base):
    level = root.replace(base, '').count(os.sep)
    if level > 1:   # limit to 2 levels
        continue

    print("üìÅ", root)

    for d in dirs:
        print("   ‚îî‚îÄ‚îÄ", d)

    print("-" * 40)

"""<brz>

# Analyzing Images

<br>

<br>

### 1. Inspect Images in Brain Tumor MRI Dataset

<br>
"""

import os
from PIL import Image

# Base paths
base_paths = [
    "/kaggle/input/brain-tumor-mri-dataset/Training",
    "/kaggle/input/brain-tumor-mri-dataset/Testing"
]

for base in base_paths:
    print(f"\nüîπ Dataset: {base}\n")

    # Loop through categories
    for category in os.listdir(base):
        category_path = os.path.join(base, category)
        if not os.path.isdir(category_path):
            continue

        print(f"Category: {category}")
        image_files = os.listdir(category_path)
        print(f"  Total Images: {len(image_files)}")

        # For image info, check first image as sample
        if len(image_files) > 0:
            sample_path = os.path.join(category_path, image_files[0])
            with Image.open(sample_path) as img:
                print(f"  Sample Image: {image_files[0]}")
                print(f"  Format: {img.format}")
                print(f"  Mode: {img.mode} (RGB/Grayscale)")
                print(f"  Size (Width x Height): {img.size}")
        print("-" * 40)

"""<br>

### Check min, max, average width/height per category. Count how many images are RGB vs grayscale.

<br>
"""

import os
from PIL import Image
import numpy as np

base = "/kaggle/input/brain-tumor-mri-dataset/Training"

for category in os.listdir(base):
    path = os.path.join(base, category)
    widths, heights = [], []
    modes = {"RGB":0, "L":0}

    for img_file in os.listdir(path):
        img_path = os.path.join(path, img_file)
        with Image.open(img_path) as img:
            w, h = img.size
            widths.append(w)
            heights.append(h)
            modes[img.mode] = modes.get(img.mode, 0) + 1

    print(f"\nCategory: {category}")
    print(f"  Total Images: {len(widths)}")
    print(f"  Width: min {min(widths)}, max {max(widths)}, avg {np.mean(widths):.1f}")
    print(f"  Height: min {min(heights)}, max {max(heights)}, avg {np.mean(heights):.1f}")
    print(f"  Modes: {modes}")

"""<br>

# Preprocessing and Saving Preprocessed Images to New Folder

<br>
"""

import os
from PIL import Image

base_paths = {
    "Training": "/kaggle/input/brain-tumor-mri-dataset/Training",
    "Testing": "/kaggle/input/brain-tumor-mri-dataset/Testing"
}
save_base = "/kaggle/working/preprocessed_dataset"
target_size = (100, 100)

for split in base_paths:
    for category in os.listdir(base_paths[split]):
        os.makedirs(os.path.join(save_base, split, category), exist_ok=True)

for split, path in base_paths.items():
    print(f"Processing {split}...")
    for category in os.listdir(path):
        src_folder = os.path.join(path, category)
        dst_folder = os.path.join(save_base, split, category)

        for img_file in os.listdir(src_folder):
            src_path = os.path.join(src_folder, img_file)
            dst_path = os.path.join(dst_folder, img_file)

            try:
                with Image.open(src_path) as img:
                    img = img.convert("RGB")
                    img = img.resize(target_size)
                    img.save(dst_path)
            except Exception as e:
                print(f"Error processing {img_file}: {e}")

    print(f"‚úÖ Done preprocessing {split} images!\n")

"""<br>

# Plotting Number of Sample in Each Category

<br>
"""

import os
import matplotlib.pyplot as plt
import numpy as np

preprocessed_base = "/kaggle/working/preprocessed_dataset"
splits = ["Training", "Testing"]

categories = os.listdir(os.path.join(preprocessed_base, "Training"))

counts = {split: [] for split in splits}
for split in splits:
    split_path = os.path.join(preprocessed_base, split)
    for category in categories:
        category_path = os.path.join(split_path, category)
        count = len([f for f in os.listdir(category_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        counts[split].append(count)

x = np.arange(len(categories))
width = 0.35

fig, ax = plt.subplots(figsize=(10,6))
rects1 = ax.bar(x - width/2, counts["Training"], width, label='Training', color='skyblue')
rects2 = ax.bar(x + width/2, counts["Testing"], width, label='Testing', color='lightgreen')

# Labels and titles
ax.set_ylabel('Number of images')
ax.set_xlabel('Category')
ax.set_title('Number of images per category (Training vs Testing)')
ax.set_xticks(x)
ax.set_xticklabels(categories)
ax.legend()
ax.grid(color = 'black')

for rects in [rects1, rects2]:
    for rect in rects:
        height = rect.get_height()
        ax.annotate('{}'.format(height),
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # offset
                    textcoords="offset points",
                    ha='center', va='bottom', fontweight='bold')

plt.show()

"""<br>

# Let's Visualize the images we are working with

<br>
"""

import os
import matplotlib.pyplot as plt
from PIL import Image

base_path = "/kaggle/working/preprocessed_dataset"
splits = ["Training", "Testing"]

samples_per_category = 3

for split in splits:
    print(f"\nüìÇ {split} Set Samples:\n")

    split_path = os.path.join(base_path, split)
    categories = os.listdir(split_path)

    for category in categories:
        category_path = os.path.join(split_path, category)
        image_files = [f for f in os.listdir(category_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        plt.figure(figsize=(12, 4))
        for i, img_file in enumerate(image_files[:samples_per_category]):
            img_path = os.path.join(category_path, img_file)
            img = Image.open(img_path)

            plt.subplot(1, samples_per_category, i+1)
            plt.imshow(img)
            plt.title(f"{category}")
            plt.axis('off')

        plt.show()

"""<br>

## Cropping the images

- Blindly resizing images to 100x100 may remove their important features or little bit part of defected area.
- So instead of Blindly resizing images to 100x100, we will cropp only the defected area part and little bit it's sorroundings so resized images don't loose their important features.

<br>

<br>

# Croping only the defected area part and little bit it's sorroundings

<br>
"""

import os
import cv2
from PIL import Image
import numpy as np

base_paths = {
    "Training": "/kaggle/input/brain-tumor-mri-dataset/Training",
    "Testing": "/kaggle/input/brain-tumor-mri-dataset/Testing"
}
save_base = "/kaggle/working/preprocessed_cropped"
target_size = (224, 224)

for split in base_paths:
    for category in os.listdir(base_paths[split]):
        os.makedirs(os.path.join(save_base, split, category), exist_ok=True)

def crop_brain_roi(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

    _, thresh = cv2.threshold(img, 10, 255, cv2.THRESH_BINARY)

    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if len(contours) == 0:
        return None

    c = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(c)

    img_color = cv2.imread(img_path)
    crop = img_color[y:y+h, x:x+w]

    crop = cv2.resize(crop, target_size)

    return crop

for split, path in base_paths.items():
    print(f"Processing {split} set...")
    for category in os.listdir(path):
        src_folder = os.path.join(path, category)
        dst_folder = os.path.join(save_base, split, category)

        for img_file in os.listdir(src_folder):
            src_path = os.path.join(src_folder, img_file)
            dst_path = os.path.join(dst_folder, img_file)

            try:
                cropped_img = crop_brain_roi(src_path)
                if cropped_img is not None:
                    cv2.imwrite(dst_path, cropped_img)
                else:
                    print(f"‚ö†Ô∏è No contour found for {img_file}")
            except Exception as e:
                print(f"Error processing {img_file}: {e}")

    print(f"‚úÖ Done preprocessing {split} images!\n")

"""<br>

# Side-by-side visualization showing original vs cropped images for Training and Testing, with 2 images per category.

<br>
"""

import os
import matplotlib.pyplot as plt
from PIL import Image
import random

original_base = "/kaggle/input/brain-tumor-mri-dataset"
cropped_base = "/kaggle/working/preprocessed_cropped"
splits = ["Training", "Testing"]
samples_per_category = 2

for split in splits:
    print(f"\nüìÇ {split} Set: Original vs Cropped Samples\n")

    split_original_path = os.path.join(original_base, split)
    split_cropped_path = os.path.join(cropped_base, split)

    categories = os.listdir(split_original_path)

    for category in categories:
        original_folder = os.path.join(split_original_path, category)
        cropped_folder = os.path.join(split_cropped_path, category)

        original_images = [f for f in os.listdir(original_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        sampled_files = random.sample(original_images, samples_per_category)

        plt.figure(figsize=(12, 4))

        for i, img_file in enumerate(sampled_files):

            img_path = os.path.join(original_folder, img_file)
            img = Image.open(img_path)
            plt.subplot(1, samples_per_category*2, i*2 + 1)
            plt.imshow(img)
            plt.title(f"Original: {category}")
            plt.axis('off')

            img_path = os.path.join(cropped_folder, img_file)
            img = Image.open(img_path)
            plt.subplot(1, samples_per_category*2, i*2 + 2)
            plt.imshow(img)
            plt.title(f"Cropped: {category}")
            plt.axis('off')

        plt.tight_layout()
        plt.show()

"""<br>

# Data Augmentation

<br>
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.resnet50 import preprocess_input

train_dir = "/kaggle/working/preprocessed_cropped/Training"
test_dir  = "/kaggle/working/preprocessed_cropped/Testing"

train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.1
)

test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=True,
    subset='training',
    seed=42
)

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=16,
    class_mode='categorical',
    subset='validation',  #
    seed=42
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

"""<br>

# Loading ResNet50

<br>
"""

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam

IMG_SIZE = (224, 224)
NUM_CLASSES = 4
LEARNING_RATE = 0.001

base_model = ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)
)

for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(NUM_CLASSES, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(
    optimizer=Adam(learning_rate=LEARNING_RATE),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

"""<br>

# Training Model

<br>
"""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

EPOCHS = 20
BATCH_SIZE = 32
MODEL_SAVE_PATH = "/kaggle/working/best_resnet50_mri.keras"

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    verbose=1,
    min_lr=1e-6
)

checkpoint = ModelCheckpoint(
    MODEL_SAVE_PATH,
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)


history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    callbacks=[early_stop, reduce_lr, checkpoint]
)

"""<br>

# Classification Report

<br>
"""

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

test_generator.reset()
y_pred_probs = model.predict(test_generator, verbose=1)
y_pred = np.argmax(y_pred_probs, axis=1)

y_true = test_generator.classes

class_labels = list(test_generator.class_indices.keys())

report = classification_report(y_true, y_pred, target_names=class_labels)
print("üìä Classification Report:\n")
print(report)

"""<br>

# Performance Check

<br>
"""

import seaborn as sns
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import pandas as pd

# Class labels
class_labels = list(test_generator.class_indices.keys())

cm = confusion_matrix(y_true, y_pred)

cm_df = pd.DataFrame(cm, index=class_labels, columns=class_labels)
print("Confusion Matrix:\n")
print(cm_df)
print('\n')

# Plot
plt.figure(figsize=(8,6))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - MRI Classification')
plt.show()

"""<br>

# Visualizing Actual vs Predicted labels of Each Category

<br>
"""

print("Class Indices =", test_generator.class_indices)
print("Index ‚Üí Label =", {v: k for k, v in test_generator.class_indices.items()})

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input

test_base = "/kaggle/working/preprocessed_cropped/Testing"
categories = os.listdir(test_base)
IMG_SIZE = (224, 224)

def load_and_preprocess(img_path):
    img = image.load_img(img_path, target_size=IMG_SIZE)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)  # ‚úÖ ResNet50 correct preprocessing
    return img_array

for category in categories:
    cat_path = os.path.join(test_base, category)
    sample_images = os.listdir(cat_path)[:3]

    for img_file in sample_images:
        img_path = os.path.join(cat_path, img_file)
        img_array = load_and_preprocess(img_path)

        pred_probs = model.predict(img_array)
        pred_class = np.argmax(pred_probs, axis=1)[0]
        pred_label = {v: k for k, v in test_generator.class_indices.items()}[pred_class]

        plt.imshow(image.load_img(img_path))
        plt.title(f"Actual: {category} | Predicted: {pred_label}")
        plt.axis('off')
        plt.show()

"""<br>

# Saving Model, Class Indices & History

<br>
"""

model_saved = model.save("final_resnet50_mri.keras")

class_indices = {'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}
import json

with open("class_indices.json", "w") as f:
    json.dump(class_indices, f)

import pickle

with open("history.pkl", "wb") as f:
    pickle.dump(history.history, f)